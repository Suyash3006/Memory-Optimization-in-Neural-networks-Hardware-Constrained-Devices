{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers , models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(trainImages , trainLabel) , (testImages , testLabel) = mnist.load_data()\n",
    "trainImages = trainImages/255.0\n",
    "testImages  = testImages/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = trainImages.reshape( -1 , 28 , 28 , 1)\n",
    "testImages = testImages.reshape(-1, 28 , 28 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.weight = self.add_weight(name='weight',\n",
    "                                      shape=(input_shape[-1], self.units),\n",
    "                                      initializer='random_normal',\n",
    "                                      trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = tf.matmul(inputs, self.weight)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "# model.add(layers.Dense(23 , aactivation = \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' , loss  = 'sparse_categorical_crossentropy',  \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 51s 26ms/step - loss: 0.1361 - accuracy: 0.9587 - val_loss: 0.0554 - val_accuracy: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e07642f970>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainImages, trainLabel, epochs=1, batch_size=32, validation_data=(testImages, testLabel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the weight matrix in the first Conv2D layer: <bound method Layer.get_weights of <keras.layers.core.dense.Dense object at 0x000002E0763A7460>>\n"
     ]
    }
   ],
   "source": [
    "# loss , accuracy  = model.evaluate(testImages , testLabel)\n",
    "# print(loss)\n",
    "# print(accuracy)\n",
    "\n",
    "\n",
    "conv1_weights = model.layers[5].get_weights\n",
    "# print(conv1_weights)\n",
    "# var = np.zeros(64)\n",
    "# for i in range(64):\n",
    "#     var[i] = i\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.plot(var  , conv1_weights)\n",
    "# plt.show()\n",
    "# print(conv1_weights)\n",
    "print(\"Shape of the weight matrix in the first Conv2D layer:\", conv1_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdDeviation = np.std(conv1_weights)\n",
    "# print(stdDeviation)\n",
    "# MeanVal = np.average(conv1_weights)\n",
    "# print(MeanVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generateCentrallisedWeight(weightArr):\n",
    "    ans = np.zeros(len(weightArr))\n",
    "    stdDeviation = np.std(weightArr)\n",
    "    MeanVal = np.average(weightArr)\n",
    "    for i in range(len(weightArr)):\n",
    "        ans[i] = random.uniform(MeanVal - stdDeviation , MeanVal + stdDeviation)\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeWeights(arr , size):\n",
    "    ans  = []\n",
    "    for i in range(size):\n",
    "        ans.append(generateCentrallisedWeight(arr[i]))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 51s 26ms/step - loss: 0.1386 - accuracy: 0.9579 - val_loss: 0.0471 - val_accuracy: 0.9835\n",
      "313/313 [==============================] - 3s 9ms/step\n",
      "[[8.91248177e-08 7.03671716e-08 2.09155805e-05 ... 9.99968171e-01\n",
      "  2.43797217e-07 7.44526858e-07]\n",
      " [1.02734535e-04 4.66749361e-06 9.99855757e-01 ... 3.30238459e-09\n",
      "  1.66662467e-05 6.68371747e-11]\n",
      " [1.14134446e-05 9.99515295e-01 5.65952141e-05 ... 6.36327968e-05\n",
      "  2.41879461e-05 1.77602953e-06]\n",
      " ...\n",
      " [1.32797096e-09 1.06182029e-06 1.34065825e-08 ... 3.17949969e-07\n",
      "  4.14662827e-05 1.16792990e-06]\n",
      " [1.72475320e-05 1.13054099e-08 5.13653937e-08 ... 3.26182914e-07\n",
      "  1.07525522e-02 8.29636065e-07]\n",
      " [9.79818105e-06 8.78471624e-08 1.60302206e-05 ... 2.93859470e-09\n",
      "  4.49196406e-04 2.66679265e-08]]\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "optimizedModel = models.Sequential()\n",
    "optimizedModel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "optimizedModel.add(layers.MaxPooling2D((2, 2)))\n",
    "optimizedModel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "optimizedModel.add(layers.MaxPooling2D((2, 2)))\n",
    "optimizedModel.add(layers.Flatten())\n",
    "optimizedModel.add(layers.Dense(64, activation='relu'))\n",
    "optimizedModel.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "size =  optimizedModel.layers[5].weights[0].shape[0]\n",
    "optimizedWeights = changeWeights(optimizedModel.layers[5].weights[0] , size)\n",
    "optimizedModel.layers[5].weights[0] = optimizedWeights\n",
    "\n",
    "size =  optimizedModel.layers[6].weights[0].shape[0]\n",
    "optimizedWeights = changeWeights(optimizedModel.layers[6].weights[0] , size)\n",
    "optimizedModel.layers[6].weights[0] = optimizedWeights\n",
    "\n",
    "optimizedModel.compile(optimizer='adam' , loss  = 'sparse_categorical_crossentropy',  metrics = ['accuracy'])\n",
    "optimizedModel.fit(trainImages, trainLabel, epochs=1, batch_size=32, validation_data=(testImages, testLabel))\n",
    "y_predict = optimizedModel.predict(testImages)\n",
    "print(y_predict)\n",
    "print(testLabel)\n",
    "# loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "# print(f'Test accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(testLabel)\n",
    "# print(testLabel.shape)\n",
    "# var = np.zeros(64)\n",
    "# for i in range(64):\n",
    "#     var[i] = i\n",
    "# plt.scatter(y_predict , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m maxpool_layer \u001b[39m=\u001b[39m MaxPooling2D((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m))(conv_layer)\n\u001b[0;32m     38\u001b[0m flatten_layer \u001b[39m=\u001b[39m Flatten()(maxpool_layer)\n\u001b[1;32m---> 39\u001b[0m custom_dense \u001b[39m=\u001b[39m CustomDense(units\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m)(flatten_layer)\n\u001b[0;32m     40\u001b[0m output_layer \u001b[39m=\u001b[39m Dense(\u001b[39m10\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)(custom_dense)\n\u001b[0;32m     42\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39minput_layer, outputs\u001b[39m=\u001b[39moutput_layer)\n",
      "File \u001b[1;32mc:\\Users\\bansa\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m, in \u001b[0;36mCustomDense.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, input_shape):\n\u001b[0;32m     16\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\u001b[39m\"\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m\"\u001b[39m, shape\u001b[39m=\u001b[39m(input_shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits))\n\u001b[1;32m---> 17\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel)\n\u001b[0;32m     19\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\u001b[39m\"\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m\"\u001b[39m, shape\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits,))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the custom dense layer\n",
    "class CustomDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None):\n",
    "        super(CustomDense, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=(input_shape[-1], self.units))\n",
    "        self.kernel[0][0] = 1\n",
    "        print(self.kernel)\n",
    "        self.bias = self.add_weight(\"bias\", shape=(self.units,))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        output = tf.matmul(inputs, self.kernel) + self.bias\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((-1, 28, 28, 1)) / 255.0\n",
    "test_images = test_images.reshape((-1, 28, 28, 1)) / 255.0\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "# Build the CNN model with the custom dense layer\n",
    "input_layer = Input(shape=(28, 28, 1))\n",
    "conv_layer = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "maxpool_layer = MaxPooling2D((2, 2))(conv_layer)\n",
    "flatten_layer = Flatten()(maxpool_layer)\n",
    "custom_dense = CustomDense(units=128, activation='relu')(flatten_layer)\n",
    "output_layer = Dense(10, activation='softmax')(custom_dense)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=1, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
